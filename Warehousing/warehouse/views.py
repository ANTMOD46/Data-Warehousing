import json
from multiprocessing.dummy import connection
from django.shortcuts import render
import requests
import os
from django.http import Http404, HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from warehouse.models import EconDailyFact, Symbol, PriceDailyFact, DateDim, Exchange, Sector,EconomicIndicator
from datetime import date
from decimal import Decimal
import time
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import io
import matplotlib
import matplotlib.pyplot as plt
import subprocess, sys
import time

API_KEY = os.getenv('T39H2CDWWA09NDT6')  # API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏≤‡∏Å Alpha Vantage
ALPHAVANTAGE_API_KEY = "<T39H2CDWWA09NDT6>"



def home(request):
    """‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ ‡πÅ‡∏•‡∏∞‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏±‡∏î‡πÑ‡∏õ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    return render(request, "home.html")


def build_api_symbol(ticker: str, exchange_code: str | None) -> str:
    t = ticker.upper()
    ex = (exchange_code or "").upper()

    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° exchange ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏∏‡∏ì)
    if ex in {"BK", "SET", "TH"}:
        return f"{t}.BK"              # ‡πÑ‡∏ó‡∏¢
    if ex in {"BSE", "BO"}:
        return f"{t}.BSE"             # ‡∏≠‡∏¥‡∏ô‡πÄ‡∏î‡∏µ‡∏¢ (BSE) ‡∏ö‡∏≤‡∏á provider ‡πÉ‡∏ä‡πâ .BO
    if ex in {"NSE", "NS"}:
        return f"{t}.NS"              # ‡∏≠‡∏¥‡∏ô‡πÄ‡∏î‡∏µ‡∏¢ (NSE)
    # ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å exchange ‡∏Å‡πá‡∏Ñ‡∏∑‡∏ô ticker ‡∏ï‡∏£‡∏á‡πÜ
    return t

def fetch_alpha_daily_adjusted(api_symbol: str):
    url = "https://www.alphavantage.co/query"
    params = {
        "function": "TIME_SERIES_DAILY_ADJUSTED",
        "symbol": api_symbol,
        "apikey": ALPHAVANTAGE_API_KEY,
        "outputsize": "full",      # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!
        "datatype": "json",
    }
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    data = r.json()
    series = data.get("Time Series (Daily)") or {}
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤->‡πÉ‡∏´‡∏°‡πà
    rows = []
    for dstr, vals in sorted(series.items()):
        rows.append({
            "date": dt.date.fromisoformat(dstr),
            "open": float(vals["1. open"]),
            "high": float(vals["2. high"]),
            "low": float(vals["3. low"]),
            "close": float(vals["4. close"]),
            "adj_close": float(vals.get("5. adjusted close", vals["4. close"])),
            "volume": int(vals["6. volume"]),
        })
    return rows

def load_into_pg(ticker: str, exchange_code: str | None = None, source="alpha"):
    api_symbol = build_api_symbol(ticker, exchange_code)

    rows = fetch_alpha_daily_adjusted(api_symbol)
    if not rows:
        raise RuntimeError(f"No data from API for {api_symbol}")

    # 2) freshness guard: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 60 ‡∏ß‡∏±‡∏ô
    max_date = rows[-1]["date"]
    if max_date < (dt.date.today() - dt.timedelta(days=60)):
        raise RuntimeError(f"Stale feed: latest={max_date} for {api_symbol}")

    with connection.cursor() as cur:
        # ‡∏´‡∏≤ symbol_id, date_id mapping
        cur.execute("SELECT id FROM dim_symbol WHERE lower(ticker)=lower(%s)", [ticker])
        res = cur.fetchone()
        if not res:
            raise RuntimeError(f"Ticker {ticker} not found in dim_symbol")
        symbol_id = res[0]

        # (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏•‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö refresh ‡∏ä‡∏±‡∏î ‡πÜ
        cur.execute("DELETE FROM fact_price_daily WHERE symbol_id=%s", [symbol_id])

        # insert ‡πÄ‡∏õ‡πá‡∏ô batch
        for r in rows:
            cur.execute("""
                INSERT INTO fact_price_daily
                (symbol_id, date_id, open, high, low, close, adj_close, volume, source, load_ts)
                VALUES (
                  %s,
                  (SELECT id FROM dim_date WHERE date=%s),
                  %s,%s,%s,%s,%s,%s,%s, now()
                )
                ON CONFLICT (symbol_id, date_id) DO UPDATE SET
                  open=EXCLUDED.open, high=EXCLUDED.high, low=EXCLUDED.low,
                  close=EXCLUDED.close, adj_close=EXCLUDED.adj_close,
                  volume=EXCLUDED.volume, source=EXCLUDED.source,
                  load_ts=EXCLUDED.load_ts
            """, [
                symbol_id, r["date"],
                r["open"], r["high"], r["low"], r["close"], r["adj_close"], r["volume"],
                source
            ])

            
# ---------- Helpers ----------
def ensure_date_dim(d: date) -> DateDim:
    q = DateDim.objects.filter(date=d)
    if q.exists():
        return q.get()
    dow = d.isoweekday()
    return DateDim.objects.create(
        date=d,
        year=d.year,
        quarter=((d.month - 1) // 3) + 1,
        month=d.month,
        day=d.day,
        day_of_week=dow,
        is_weekend=(dow >= 6)
    )

def ensure_exchange(exchange_code: str) -> Exchange:
    obj, _ = Exchange.objects.get_or_create(code=exchange_code, defaults={"name": exchange_code})
    return obj

def ensure_sector(sector_code: str) -> Sector:
    obj, _ = Sector.objects.get_or_create(code=sector_code, defaults={"name": sector_code})
    return obj

def ensure_indicator(code: str, name: str = "", unit: str = "") -> EconomicIndicator:
    obj, created = EconomicIndicator.objects.get_or_create(
        code=code, defaults={"name": name or code, "unit": unit or ""}
    )
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡∏∑‡πà‡∏≠/‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
    changed = False
    if name and obj.name != name:
        obj.name = name; changed = True
    if unit and obj.unit != unit:
        obj.unit = unit; changed = True
    if changed:
        obj.save(update_fields=["name", "unit"])
    return obj

def backoff_fetch(url: str, tries: int = 2):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API; ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ Note/Information (rate limit) ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á"""
    for i in range(tries):
        r = requests.get(url, timeout=60)
        try:
            data = r.json()
        except Exception:
            data = {"_raw": r.text}
        note = (data.get("Note") or data.get("Information") or "").lower()
        if ("thank you for using alpha vantage" in note) or ("frequency" in note):
            if i + 1 < tries:
                time.sleep(20)
                continue
        return r.status_code, data
    return r.status_code, data



def get_stock_data(symbol_ticker):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Alpha Vantage API"""
    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol_ticker}&apikey={API_KEY}&outputsize=full'
    
    try:
        response = requests.get(url)
        data = response.json()

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API limit ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if "Note" in data:
            # ‡∏ñ‡πâ‡∏≤ API limit ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡∏£‡∏≠ 1 ‡∏ô‡∏≤‡∏ó‡∏µ
            time.sleep(60)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 1 ‡∏ô‡∏≤‡∏ó‡∏µ
            return get_stock_data(symbol_ticker)  # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å API
        if 'Time Series (Daily)' not in data:
            return None  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ return None

        return data['Time Series (Daily)']
    except Exception as e:
        print(f"Error fetching data: {e}")
        return None


@csrf_exempt
def load_stock_data(request, symbol_ticker):
    if request.method == "GET":
        symbol = symbol_ticker.upper()
        time_series = get_stock_data(symbol)
        if not time_series:
            return JsonResponse({"error": "Data not found or API limit reached."}, status=400)

        exchange = ensure_exchange("NASDAQ")
        sector = ensure_sector("TECHNOLOGY")
        symbol_obj, created = Symbol.objects.get_or_create(
            ticker=symbol,
            defaults={
                "name": symbol,
                "exchange": exchange,
                "sector": sector,
                "currency": "USD",
            }
        )

        inserted = 0
        updated = 0
        for date_str, stats in time_series.items():
            stock_date = date.fromisoformat(date_str)
            date_obj = ensure_date_dim(stock_date)

            open_price = Decimal(stats["1. open"])
            high_price = Decimal(stats["2. high"])
            low_price = Decimal(stats["3. low"])
            close_price = Decimal(stats["4. close"])
            adj_close = Decimal(stats.get("5. adjusted close", close_price))
            volume = int(stats.get("6. volume") or stats.get("5. volume", 0))

            price_data, created = PriceDailyFact.objects.update_or_create(
                symbol=symbol_obj,
                date=date_obj,
                defaults={
                    'open': open_price,
                    'high': high_price,
                    'low': low_price,
                    'close': close_price,
                    'adj_close': adj_close,
                    'volume': volume,
                    'source': "alpha_vantage",
                }
            )

            if created:
                inserted += 1
            else:
                updated += 1

        # üîΩ ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°: trigger sync ‡πÑ‡∏õ ClickHouse
        try:
            subprocess.run(
                ["wsl.exe", "bash", "-lc", f"/home/exit/sync_symbol.sh {symbol}"],
                check=True, capture_output=True, text=True
            )
        except subprocess.CalledProcessError as e:
            print("CH sync failed:", e.stdout, e.stderr, file=sys.stderr)

        return JsonResponse({
            "message": f"Data for {symbol} processed. Inserted: {inserted}, Updated: {updated}"
        }, status=200)
    

def get_economic_data():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏à‡∏≤‡∏Å Alpha Vantage"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á URLs ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
    urls = {
        "CPI": f"https://www.alphavantage.co/query?function=CPI&apikey={API_KEY}",
        "REAL_GDP": f"https://www.alphavantage.co/query?function=REAL_GDP&apikey={API_KEY}",
        "UNEMPLOYMENT": f"https://www.alphavantage.co/query?function=UNEMPLOYMENT&apikey={API_KEY}",
    }

    data = {}
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ó‡∏±‡πâ‡∏á 3 ‡∏ï‡∏±‡∏ß
    for key, url in urls.items():
        try:
            response = requests.get(url)
            response_data = response.json()

            if 'Note' in response_data or 'Information' in response_data:
                data[key] = {"error": "API limit reached or issue with the data."}
            else:
                data[key] = response_data
        except Exception as e:
            data[key] = {"error": str(e)}

    return data

@csrf_exempt
def get_economic_indicators(request):
    """API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
    if request.method == "GET":
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        economic_data = get_economic_data()

        return JsonResponse(economic_data, status=200)

# ---------- Economic Indicators ----------
def parse_econ_payload(payload: dict):
    name = payload.get("name") or payload.get("Name") or ""
    unit = payload.get("unit") or payload.get("Unit") or ""
    rows = []
    items = payload.get("data") or payload.get("Data") or payload.get("Historical Data")
    if isinstance(items, list):
        for row in items:
            ds = row.get("date") or row.get("Date")
            val = row.get("value") or row.get("Value")
            if not ds:
                continue
            try:
                d = date.fromisoformat(ds)
            except Exception:
                continue
            try:
                v = Decimal(str(val)) if val not in (None, "", "None") else None
            except Exception:
                v = None
            rows.append((d, v))
    return name, unit, rows

@csrf_exempt
def load_economic_indicators(request):
    """
    ‡∏î‡∏∂‡∏á + ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏à‡∏≤‡∏Å Alpha Vantage ‚Üí Postgres
    ‡πÅ‡∏•‡πâ‡∏ß '‡∏ã‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏õ ClickHouse ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ indicator (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å WSL: /home/exit/sync_econ.sh <CODE>)

    ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå:
      - ?codes=CPI,REAL_GDP,UNEMPLOYMENT (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma)
      - ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß: ?code=CPI&code=REAL_GDP
      - ?sync=0  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà trigger sync ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡πÉ‡∏´‡πâ cron ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏á)

    ‡∏Ñ‡πà‡∏≤‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡πà‡∏á codes: ["CPI", "REAL_GDP", "UNEMPLOYMENT"]
    """
    if request.method != "GET":
        return JsonResponse({"error": "GET only"}, status=405)

    # ----- ‡∏≠‡πà‡∏≤‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå -----
    default_codes = ["CPI", "REAL_GDP", "UNEMPLOYMENT"]

    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á ?codes=... ‡πÅ‡∏•‡∏∞ ?code=... ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    codes_param = request.GET.get("codes")
    codes_list  = request.GET.getlist("code")

    codes = []
    if codes_param:
        codes.extend([c.strip().upper() for c in codes_param.split(",") if c.strip()])
    if codes_list:
        codes.extend([c.strip().upper() for c in codes_list if c.strip()])

    if not codes:
        codes = default_codes

    # ‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏î‡∏¥‡∏°
    seen = set()
    uniq_codes = []
    for c in codes:
        if c not in seen:
            seen.add(c)
            uniq_codes.append(c)

    # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡πà‡∏≤‡∏à‡∏∞ sync ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÑ‡∏´‡∏° (‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå: sync)
    do_sync = request.GET.get("sync", "1") != "0"

    result = {
        "inserted": 0,
        "updated": 0,
        "by_indicator": {}
    }

    for code in uniq_codes:
        url = f"https://www.alphavantage.co/query?function={code}&apikey={API_KEY}"
        status, payload = backoff_fetch(url)

        # ‡∏ñ‡πâ‡∏≤ key ‡∏´‡∏≤‡∏¢/‡∏ï‡∏¥‡∏î‡∏•‡∏¥‡∏°‡∏¥‡∏ï/‡∏ï‡πâ‡∏≠‡∏á premium ‚Üí ‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡πÑ‡∏õ
        if status != 200:
            result["by_indicator"][code] = {"error": f"http {status}"}
            continue

        name, unit, rows = parse_econ_payload(payload)
        if not rows:
            note = payload.get("Note") or payload.get("Information") or payload.get("Error Message") or str(payload)[:300]
            result["by_indicator"][code] = {"error": note}
            continue

        indicator = ensure_indicator(code, name=name, unit=unit)

        ins = 0
        upd = 0
        for d, v in rows:
            # d ‡∏Ñ‡∏∑‡∏≠ datetime.date (‡∏´‡∏£‡∏∑‡∏≠ string 'YYYY-MM-DD'), v ‡∏Ñ‡∏∑‡∏≠ Decimal/float
            the_date = d if isinstance(d, date) else date.fromisoformat(str(d))
            dd = ensure_date_dim(the_date)
            obj, created = EconDailyFact.objects.update_or_create(
                indicator=indicator,
                date=dd,
                defaults={
                    "value": Decimal(str(v)),
                    "source": "alpha"
                }
            )
            if created:
                ins += 1
            else:
                upd += 1

        result["inserted"] += ins
        result["updated"] += upd
        result["by_indicator"][code] = {
            "name": indicator.name,
            "unit": indicator.unit,
            "rows_in_payload": len(rows),
            "inserted": ins,
            "updated": upd,
        }

        # ----- Trigger sync ‡πÑ‡∏õ ClickHouse ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ï‡πà‡∏≠ indicator -----
        if do_sync:
            try:
                proc = subprocess.run(
                    ["wsl.exe", "bash", "-lc", f"/home/exit/sync_econ.sh {code}"],
                    check=True, capture_output=True, text=True
                )
                result["by_indicator"][code]["ch_sync"] = "ok"
                # (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ) ‡πÄ‡∏Å‡πá‡∏ö stdout ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÑ‡∏ß‡πâ‡∏î‡∏π‡∏î‡∏µ‡∏ö‡∏±‡∏Å
                if proc.stdout:
                    result["by_indicator"][code]["ch_sync_out"] = proc.stdout.strip().splitlines()[-1][:200]
            except subprocess.CalledProcessError as e:
                result["by_indicator"][code]["ch_sync"] = "failed"
                result["by_indicator"][code]["ch_sync_err"] = (e.stderr or e.stdout or "").strip()[:400]
                
                if code != uniq_codes[-1]:
                    time.sleep(15) 


    return JsonResponse(result, status=200)


# from django.shortcuts import render
# from .models import EconDailyFact

# def economic_indicators_view(request):
#     # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CPI)
#     data = EconDailyFact.objects.all()  # ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥ query ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

#     # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á template
#     return render(request, 'economic_indicators.html', {'data': data})
from .models import EconDailyFact, EconomicIndicator
def economic_indicators_view(request):
    
    # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CPI
    cpi_indicator = EconomicIndicator.objects.get(code='CPI') # ‡∏î‡∏∂‡∏á Indicator object ‡∏Ç‡∏≠‡∏á CPI
    cpi_data = EconDailyFact.objects.filter(indicator=cpi_indicator).order_by('-date')

    # 2. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GDP
    gdp_indicator = EconomicIndicator.objects.get(code='REAL_GDP')
    gdp_data = EconDailyFact.objects.filter(indicator=gdp_indicator).order_by('-date')
    
    # 3. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• UNEMPLOYMENT
    unemp_indicator = EconomicIndicator.objects.get(code='UNEMPLOYMENT')
    unemp_data = EconDailyFact.objects.filter(indicator=unemp_indicator).order_by('-date')

    context = {
        'cpi_data': cpi_data,
        'gdp_data': gdp_data,
        'unemp_data': unemp_data,
    }
    
    return render(request, 'economic_indicators.html', context)

# ---------- ClickHouse ‡∏Å‡∏•‡πâ‡∏≤ 
#clickhouse

# from django.http import JsonResponse
# from django.db import connections


# def stock_chart_page(request, ticker: str):
#     # 1) ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dropdown ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
#     with connections["clickhouse"].cursor() as cur:
#         cur.execute("""
#             SELECT DISTINCT s.ticker
#             FROM market.dim_symbol AS s
#             /* ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ INNER JOIN fact ‡πÅ‡∏ó‡∏ô ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á DISTINCT */
#             -- INNER JOIN market.fact_price_daily f ON f.symbol_id = s.id
#             WHERE s.is_active = 1
#             ORDER BY s.ticker
#         """)
#         symbol_rows = cur.fetchall()
#     symbols = [r[0] for r in symbol_rows]

#     # ‡∏´‡∏≤‡∏Å ticker ‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏°‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡πÇ‡∏¢‡∏ô 404 (‡∏Å‡∏±‡∏ô‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î)
#     if ticker not in symbols:
#         # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡πá‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ
#         pass

#     # 2) ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Äú‡∏ß‡∏±‡∏ô‡∏•‡∏∞ 1 ‡πÅ‡∏ñ‡∏ß‚Äù ‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 30 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
#     sql = """
#       SELECT
#         d.date,
#         argMax(f.open,      f.load_ts)  AS open,
#         argMax(f.high,      f.load_ts)  AS high,
#         argMax(f.low,       f.load_ts)  AS low,
#         argMax(f.close,     f.load_ts)  AS close,
#         argMax(f.adj_close, f.load_ts)  AS adj_close,
#         argMax(f.volume,    f.load_ts)  AS volume
#       FROM market.fact_price_daily f
#       JOIN market.dim_date  d ON d.id = f.date_id
#       JOIN market.dim_symbol s ON s.id = f.symbol_id
#       WHERE s.ticker = %(ticker)s
#       GROUP BY d.date
#       ORDER BY d.date DESC
#       LIMIT 30
#     """
#     with connections["clickhouse"].cursor() as cur:
#         cur.execute(sql, {"ticker": ticker})
#         rows = cur.fetchall()

#     if not rows:
#         raise Http404(f"No data for ticker={ticker}")

#     # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡πà‡∏≤‚Üí‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
#     rows.reverse()

#     labels   = [r[0].isoformat() for r in rows]
#     opens    = [float(r[1]) if r[1] is not None else None for r in rows]
#     highs    = [float(r[2]) if r[2] is not None else None for r in rows]
#     lows     = [float(r[3]) if r[3] is not None else None for r in rows]
#     closes   = [float(r[4]) if r[4] is not None else None for r in rows]
#     adjclose = [float(r[5]) if r[5] is not None else None for r in rows]
#     volumes  = [int(r[6])   if r[6] is not None else None for r in rows]

#     context = {
#         "ticker": ticker,
#         "symbols": symbols,  # ‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö dropdown
#         "labels_json":   json.dumps(labels),
#         "opens_json":    json.dumps(opens),
#         "highs_json":    json.dumps(highs),
#         "lows_json":     json.dumps(lows),
#         "closes_json":   json.dumps(closes),
#         "adjclose_json": json.dumps(adjclose),
#         "volumes_json":  json.dumps(volumes),
#     }
#     return render(request, "stock_chart.html", context)



# ‡∏°‡∏î‡∏õ‡∏¥‡∏î
# from django.shortcuts import render
# from django.db import connections
# from django.http import Http404
# import json

# def stock_chart_page(request, ticker: str):
#     # 1) ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dropdown ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
#     with connections["clickhouse"].cursor() as cur:
#         cur.execute("""
#             SELECT DISTINCT s.ticker
#             FROM market.dim_symbol AS s
#             WHERE s.is_active = 1
#               AND s.id IN (SELECT DISTINCT symbol_id FROM market.fact_price_daily)
#             ORDER BY s.ticker
#         """)
#         symbols = [row[0] for row in cur.fetchall()]

#     # ‡∏ñ‡πâ‡∏≤ ticker ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÉ‡∏´‡πâ 404
#     if ticker not in symbols:
#         raise Http404(f"Ticker not found: {ticker}")

#     # 2) ‡πÄ‡∏≠‡∏≤ 30 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ß‡∏±‡∏ô‡∏•‡∏∞ 1 ‡πÅ‡∏ñ‡∏ß) ‡πÉ‡∏ä‡πâ argMax ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° load_ts
#     sql = """
#         SELECT
#             d.date AS dt,
#             argMax(f.`open`,     f.load_ts) AS open,
#             argMax(f.high,       f.load_ts) AS high,
#             argMax(f.low,        f.load_ts) AS low,
#             argMax(f.`close`,    f.load_ts) AS close,
#             argMax(f.adj_close,  f.load_ts) AS adj_close,
#             argMax(f.volume,     f.load_ts) AS volume
#         FROM market.fact_price_daily AS f
#         INNER JOIN market.dim_date AS d ON d.id = f.date_id
#         WHERE f.symbol_id IN (
#             SELECT id FROM market.dim_symbol
#             WHERE ticker = %(ticker)s AND is_active = 1
#         )
#         GROUP BY dt
#         ORDER BY dt DESC
#         LIMIT 30
#     """
#     with connections["clickhouse"].cursor() as cur:
#         cur.execute(sql, {"ticker": ticker})
#         rows = cur.fetchall()

#     if not rows:
#         raise Http404(f"No data for ticker={ticker}")

#     # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤->‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
#     rows.reverse()

#     labels   = [r[0].isoformat() for r in rows]
#     opens    = [float(r[1]) if r[1] is not None else None for r in rows]
#     highs    = [float(r[2]) if r[2] is not None else None for r in rows]
#     lows     = [float(r[3]) if r[3] is not None else None for r in rows]
#     closes   = [float(r[4]) if r[4] is not None else None for r in rows]
#     adjclose = [float(r[5]) if r[5] is not None else None for r in rows]
#     volumes  = [int(r[6])   if r[6] is not None else None for r in rows]

#     context = {
#         "ticker": ticker,
#         "symbols": symbols,
#         "labels_json":   json.dumps(labels),
#         "opens_json":    json.dumps(opens),
#         "highs_json":    json.dumps(highs),
#         "lows_json":     json.dumps(lows),
#         "closes_json":   json.dumps(closes),
#         "adjclose_json": json.dumps(adjclose),
#         "volumes_json":  json.dumps(volumes),
#     }
#     return render(request, "stock_chart.html", context)





from django.shortcuts import render
from django.db import connections
from django.http import Http404, JsonResponse
import json
import pandas as pd
from datetime import timedelta

def stock_chart_page(request, ticker: str):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á (ClickHouse)
    ‡∏û‡∏£‡πâ‡∏≠‡∏° RSI, MACD, Timeframe filter (1M, 3M, 1Y, 5Y)
    """
    timeframe = request.GET.get("period", "1M")  # default = 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô

    # üïí Map ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô
    period_map = {
        "1D": 1,
        "1W": 7,
        "1M": 30,
        "3M": 90,
        "1Y": 365,
        "5Y": 365 * 5,
    }
    days = period_map.get(timeframe, 30)

    # 1) ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏à‡∏£‡∏¥‡∏á)
    with connections["clickhouse"].cursor() as cur:
        cur.execute("""
            SELECT DISTINCT s.ticker
            FROM market.dim_symbol AS s
            WHERE s.is_active = 1
              AND s.id IN (SELECT DISTINCT symbol_id FROM market.fact_price_daily)
            ORDER BY s.ticker
        """)
        symbols = [r[0] for r in cur.fetchall()]

    if ticker not in symbols:
        raise Http404(f"Ticker not found: {ticker}")

    # 2) ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏≤‡∏° period
    sql = f"""
        SELECT
            d.date AS dt,
            argMax(f.open,  f.load_ts) AS open,
            argMax(f.high,  f.load_ts) AS high,
            argMax(f.low,   f.load_ts) AS low,
            argMax(f.close, f.load_ts) AS close,
            argMax(f.volume,f.load_ts) AS volume
        FROM market.fact_price_daily AS f
        INNER JOIN market.dim_date AS d ON d.id = f.date_id
        WHERE f.symbol_id IN (
            SELECT id FROM market.dim_symbol WHERE ticker = %(ticker)s AND is_active = 1
        )
        GROUP BY dt
        ORDER BY dt DESC
        LIMIT {days + 20}
    """

    with connections["clickhouse"].cursor() as cur:
        cur.execute(sql, {"ticker": ticker})
        rows = cur.fetchall()

    if not rows:
        raise Http404(f"No data found for {ticker}")

    df = pd.DataFrame(rows, columns=["date", "open", "high", "low", "close", "volume"]).sort_values("date")

    # ‚úÖ 1) ‡πÅ‡∏õ‡∏•‡∏á date ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô datetime ‡∏à‡∏£‡∏¥‡∏á
    df["date"] = pd.to_datetime(df["date"])

    # ‚úÖ 2) ‡πÅ‡∏õ‡∏•‡∏á numeric columns ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô float/int
    for col in ["open", "high", "low", "close", "volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")


    # === RSI (14) ===
    delta = df["close"].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=14).mean()
    avg_loss = loss.rolling(window=14).mean()
    rs = avg_gain / avg_loss
    df["rsi"] = 100 - (100 / (1 + rs))

    # === MACD (12,26,9) ===
    ema12 = df["close"].ewm(span=12, adjust=False).mean()
    ema26 = df["close"].ewm(span=26, adjust=False).mean()
    df["macd"] = ema12 - ema26
    df["signal"] = df["macd"].ewm(span=9, adjust=False).mean()

    # === ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏à‡∏£‡∏¥‡∏á ===
    closes = df["close"].tolist()
    highs = df["high"].tolist()
    lows = df["low"].tolist()
    volumes = df["volume"].tolist()

    if len(closes) >= 2:
        diff = closes[-1] - closes[-2]
        pct = (diff / closes[-2]) * 100 if closes[-2] else 0
        change_text = f"{diff:+.2f} ({pct:+.2f}%)"
    else:
        change_text = "-"

    high_52w = max(highs) if highs else None
    low_52w = min(lows) if lows else None
    avg_volume = (sum(volumes) / len(volumes) / 1_000_000) if volumes else None

    # ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ Template
    context = {
        "ticker": ticker,
        "symbols": symbols,
        "timeframe": timeframe,
        "labels_json": json.dumps(df["date"].dt.strftime("%Y-%m-%d").tolist()),
        "closes_json": json.dumps(df["close"].round(2).tolist()),
        "volumes_json": json.dumps(df["volume"].astype(int).tolist()),
        "rsi_json": json.dumps(df["rsi"].round(2).fillna(0).tolist()),
        "macd_json": json.dumps(df["macd"].round(4).fillna(0).tolist()),
        "signal_json": json.dumps(df["signal"].round(4).fillna(0).tolist()),
        "change_text": change_text,
        "high_52w": high_52w,
        "low_52w": low_52w,
        "avg_volume": avg_volume,
        "periods": ["1M", "3M", "1Y", "5Y"],   # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    }

    return render(request, "stock_chart.html", context)









###‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Google Gemini API
import os
import google.generativeai as genai
from django.db import connections
from django.shortcuts import render
from django.views.decorators.csrf import csrf_exempt
from django.http import JsonResponse
import json


genai.configure(api_key="AIzaSyCv3HKt9M-SkeAv9Tk3JhJpmr7uH6s9j-A")
model = genai.GenerativeModel("gemini-2.5-flash")

def fetch_price_data(ticker: str, days: int = 30):
    """
    ‡∏î‡∏∂‡∏á OHLCV ‡∏ß‡∏±‡∏ô‡∏•‡∏∞ 1 ‡πÅ‡∏ñ‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢ argMax ‡∏ï‡∏≤‡∏° load_ts)
    """
    sql = """
      SELECT
        d.date,
        argMax(f.open,      f.load_ts) AS open,
        argMax(f.high,      f.load_ts) AS high,
        argMax(f.low,       f.load_ts) AS low,
        argMax(f.close,     f.load_ts) AS close,
        argMax(f.adj_close, f.load_ts) AS adj_close,
        argMax(f.volume,    f.load_ts) AS volume
      FROM market.fact_price_daily f
      JOIN market.dim_symbol s ON s.id=f.symbol_id
      JOIN market.dim_date   d ON d.id=f.date_id
      WHERE lower(s.ticker) = %(ticker)s
      GROUP BY d.date
      ORDER BY d.date DESC
      LIMIT %(days)s
    """
    with connections["clickhouse"].cursor() as cur:
        cur.execute(sql, {"ticker": ticker.lower(), "days": days})
        rows = cur.fetchall()

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤ -> ‡πÉ‡∏´‡∏°‡πà
    return rows[::-1]

def fetch_econ_data(code: str, months: int = 12):
    sql = """
      SELECT d.date, f.value
      FROM market.fact_econ_daily f
      JOIN market.dim_econ_indicator i ON i.id=f.indicator_id
      JOIN market.dim_date d ON d.id=f.date_id
      WHERE lower(i.code) = %(code)s
      ORDER BY d.date DESC
      LIMIT %(months)s
    """
    with connections["clickhouse"].cursor() as cur:
        cur.execute(sql, {"code": code.lower(), "months": months})
        rows = cur.fetchall()
    return rows[::-1]

# def ask_ai_about_stock(ticker: str):
#     prices = fetch_price_data(ticker)
#     table_txt = "\n".join([f"{d} O:{o} H:{h} L:{l} C:{c} V:{v}" for d,o,h,l,c,v in prices])

#     prompt = f"""
#     ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô {ticker} 30 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:
#     {table_txt}

#     ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ö‡∏ß‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏ö?
#     """
#     resp = model.generate_content(prompt)
#     return resp.text

# def ask_ai_about_econ(indicator: str):
#     econ = fetch_econ_data(indicator)
#     table_txt = "\n".join([f"{d} {val}" for d,val in econ])

#     prompt = f"""
#     ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à ({indicator}) 12 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:
#     {table_txt}

#     ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏á ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ï‡πà‡∏≠‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏•‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
#     """
#     resp = model.generate_content(prompt)
#     return resp.text



# from django.http import JsonResponse

# def ai_stock_analysis(request, ticker: str):
#     text = ask_ai_about_stock(ticker)
#     return JsonResponse({"ticker": ticker, "analysis": text})

# def ai_econ_analysis(request, code: str):
#     text = ask_ai_about_econ(code)
#     return JsonResponse({"indicator": code, "analysis": text})








@csrf_exempt
def ai_prompt_page(request):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå prompt ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÉ‡∏´‡πâ Gemini
    """
    if request.method == "POST":
        try:
            data = json.loads(request.body.decode())
            user_prompt = data.get("prompt", "")
            if not user_prompt:
                return JsonResponse({"error": "empty prompt"}, status=400)

            resp = model.generate_content(user_prompt)
            return JsonResponse({"response": resp.text})
        except Exception as e:
            return JsonResponse({"error": str(e)}, status=500)

    # GET ‚Üí render ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
    return render(request, "ai_prompt.html")




def ch_all_tickers():
    with connections["clickhouse"].cursor() as cur:
        cur.execute("""
            SELECT DISTINCT s.ticker
            FROM market.dim_symbol s
            WHERE s.is_active = 1
            ORDER BY s.ticker
        """)
        return [r[0] for r in cur.fetchall()]










# ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£ import connections ‡∏à‡∏≤‡∏Å django.db
# from django.db import connections 

def ch_fetch_price(ticker: str, days: int = 30):
    """
    ‡∏î‡∏∂‡∏á OHLCV ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Zero-JOIN (‡∏´‡∏•‡∏≤‡∏¢ Query) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î Multiple JOINs ‡∏Ç‡∏≠‡∏á ClickHouse
    """
    
    with connections["clickhouse"].cursor() as cur:
        
        # 1. A. Query 1: Get Symbol ID (Zero JOIN)
        cur.execute(
            "SELECT id FROM market.dim_symbol WHERE lower(ticker) = %(ticker)s", 
            {"ticker": ticker.lower()}
        )
        symbol_row = cur.fetchone()
        if not symbol_row:
            # ‡∏Ñ‡∏ß‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Error 404 ‡πÉ‡∏ô Django view ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ
            raise Exception(f"Ticker '{ticker}' not found in dim_symbol.")
        symbol_id = symbol_row[0]
        
        # 1. B. Query 2: Get Date IDs and the actual date (Zero JOIN)
        # ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞ ID ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô 30 ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
        date_sql = f"""
        SELECT 
            id, date 
        FROM market.dim_date 
        WHERE date >= today() - INTERVAL %(days)s DAY 
        ORDER BY date ASC
        """
        cur.execute(date_sql, {"days": days})
        date_rows = cur.fetchall()
        
        if not date_rows:
            return [] # ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ
            
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á ID ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Python
        date_lookup = {row[0]: row[1] for row in date_rows}
        date_id_filter = ", ".join(map(str, date_lookup.keys()))
        
        
        # 2. Query 3: Main Fact Data (Zero JOIN)
        # ‡πÉ‡∏ä‡πâ symbol_id ‡πÅ‡∏•‡∏∞ date_id ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Fact Table
        main_sql = f"""
        SELECT
            f.date_id,
            argMax(f.open, f.load_ts) AS open,
            argMax(f.high, f.load_ts) AS high,
            argMax(f.low, f.load_ts) AS low,
            argMax(f.close, f.load_ts) AS close,
            argMax(f.adj_close, f.load_ts) AS adj_close,
            argMax(f.volume, f.load_ts) AS volume
        FROM market.fact_price_daily f
        WHERE f.symbol_id = %(symbol_id)s
          AND f.date_id IN ({date_id_filter}) 
        GROUP BY f.date_id
        ORDER BY f.date_id ASC
        """
        
        # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ date_id_filter ‡πÄ‡∏õ‡πá‡∏ô string ‡πÉ‡∏ô SQL Query 
        # ‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á symbol_id ‡πÅ‡∏¢‡∏Å‡πÑ‡∏õ
        cur.execute(main_sql, {"symbol_id": symbol_id})
        fact_rows = cur.fetchall()
        
    # 3. Combine results in Python (‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£ JOIN)
    final_rows = []
    for date_id, open_p, high_p, low_p, close_p, adj_close_p, volume_p in fact_rows:
        date_str = date_lookup.get(date_id)
        if date_str:
            # ‡∏ô‡∏≥‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Dictionary ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
            final_rows.append((date_str, open_p, high_p, low_p, close_p, adj_close_p, volume_p))

    # ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤ -> ‡πÉ‡∏´‡∏°‡πà (ASC) ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß
    return final_rows # [(date, open, high, low, close, adj_close, volume), ...]

def ch_fetch_econ(code: str, npoints: int = 12):
    """
    ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à 12 ‡∏à‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ß‡∏±‡∏ô‡∏•‡∏∞ 1 ‡πÅ‡∏ñ‡∏ß) ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤‚Üí‡πÉ‡∏´‡∏°‡πà
    """
    sql = """
      SELECT
        d.date,
        argMax(f.value, f.load_ts) AS value
      FROM market.fact_econ_daily f
      JOIN market.dim_econ_indicator i ON i.id=f.indicator_id
      JOIN market.dim_date d ON d.id=f.date_id
      WHERE lower(i.code) = %(code)s
      GROUP BY d.date
      ORDER BY d.date DESC
      LIMIT %(n)s
    """
    with connections["clickhouse"].cursor() as cur:
        cur.execute(sql, {"code": code.lower(), "n": npoints})
        rows = cur.fetchall()
    rows.reverse()
    return rows  # [(date, value), ...]

# ---------- Page: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏∏‡πâ‡∏ô + prompt + ‡∏ú‡∏• AI ----------
def ai_stock_page(request):
    symbols = ch_all_tickers()
    # preselect ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    return render(request, "ai_stock.html", {"symbols": symbols, "default_days": 30})








# ---------- API: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏∏‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ClickHouse + prompt ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ----------
from django.http import JsonResponse, Http404
from django.views.decorators.csrf import csrf_exempt
import json

import google.generativeai as genai
# ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î API Key ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
genai.configure(api_key="AIzaSyCv3HKt9M-SkeAv9Tk3JhJpmr7uH6s9j-A") 
model = genai.GenerativeModel("gemini-2.5-flash") # ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ








# ‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ä‡πâ‡∏î‡∏µ‡∏°‡∏î‡∏õ‡∏¥‡∏î
# import json
# from django.http import JsonResponse
# from django.views.decorators.csrf import csrf_exempt
# from datetime import date, timedelta
# from typing import List, Tuple, Any


# @csrf_exempt
# def ai_analyze_stock(request):
#     if request.method != "POST":
#         return JsonResponse({"error": "POST only"}, status=405)

#     # 1. Parse body (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)
#     try:
#         payload = json.loads(request.body.decode())
#     except Exception:
#         return JsonResponse({"error": "invalid json body"}, status=400)

#     ticker      = (payload.get("ticker") or "").strip()
#     days        = int(payload.get("days") or 30)
#     user_prompt = (payload.get("prompt") or "").strip()
#     econ_code   = (payload.get("econ_code") or "").strip()

#     if not ticker:
#         return JsonResponse({"error": "ticker is required"}, status=400)

#     rows = []
#     # 2. ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å CH (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠/‡∏Ñ‡∏¥‡∏ß‡∏£‡∏µ)
#     try:
#         rows = ch_fetch_price(ticker, days=days)
#     except Exception as e:
#         # ‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î
#         return JsonResponse({"error": f"Database fetch error: {e}"}, status=500)
        
#     if not rows:
#         # ‡πÅ‡∏Å‡πâ Http404 ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô JsonResponse 404
#         return JsonResponse({"error": f"No data for ticker={ticker}"}, status=404)

#     # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)
#     price_lines = []
#     for d, o, h, l, c, adjc, v in rows:
#         o = float(o) if o is not None else None
#         h = float(h) if h is not None else None
#         l = float(l) if l is not None else None
#         c = float(c) if c is not None else None
#         adjc = float(adjc) if adjc is not None else None
#         v = int(v) if v is not None else 0
#         price_lines.append(f"{d} O:{o} H:{h} L:{l} C:{c} AdjC:{adjc} V:{v}")
#     price_block = "\n".join(price_lines)

#     econ_block = ""
#     if econ_code:
#         try:
#             econ = ch_fetch_econ(econ_code, npoints=12)
#             if econ:
#                 econ_lines = [f"{d} {float(val) if val is not None else 'null'}" for d, val in econ]
#                 econ_block = "\n\n‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à ({}) 12 ‡∏à‡∏∏‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n{}".format(econ_code, "\n".join(econ_lines))
#         except Exception as e:
#             # ‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö crash
#             econ_block = f"\n\n[Warning: Failed to fetch econ data ({e})]"


#     # 3. prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini (‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
#     SYSTEM_PROMPT = (
#         # ... (‡∏™‡πà‡∏ß‡∏ô SYSTEM_PROMPT ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå) ...
#     ) # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏´‡∏ô‡∏î SYSTEM_PROMPT ‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô Global/Module Variable ‡πÅ‡∏•‡πâ‡∏ß

#     # ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á prompt ‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
#     prompt = (
#         f"{SYSTEM_PROMPT}" 
#         f"--- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---\n"
#         f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô {ticker} {days} ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤‚Üí‡πÉ‡∏´‡∏°‡πà):\n"
#         f"{price_block}\n"
#         f"{econ_block}"
#         f"--- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---\n"
#         f"‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô **{ticker}** ‡πÇ‡∏î‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:\n"
#         f"1. **‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏´‡∏•‡∏±‡∏Å (Trend)** ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á {days} ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô/‡∏•‡∏á, Sideways)\n"
#         f"2. **‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ï‡πâ‡∏≤‡∏ô (Support/Resistance)** ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô\n"
#         f"3. **‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞** ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢ (Volume) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ (Volatility)\n"
#         f"4. **‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤** ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏°\n"
#     )

#     if user_prompt:
#         prompt += f"\n--- ‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ---\n"
#         prompt += f"{user_prompt}\n"
#         prompt += f"‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢\n"


#     # 4. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)
#     try:
#         resp = model.generate_content(prompt)
#         answer = resp.text
#     except Exception as e:
#         # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ Try/Catch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ Gemini/OpenAI API ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
#         return JsonResponse({"error": f"Gemini API error: {e}"}, status=500)

#     # 5. response
#     return JsonResponse({
#         "ticker": ticker,
#         "days": days,
#         "used_econ": econ_code or None,
#         "analysis": answer,
       
#     }, status=200)


@csrf_exempt
def ai_analyze_stock(request):
    if request.method != "POST":
        return JsonResponse({"error": "POST only"}, status=405)

    try:
        payload = json.loads(request.body.decode())
    except Exception:
        return JsonResponse({"error": "invalid json body"}, status=400)

    ticker      = (payload.get("ticker") or "").strip()
    days        = int(payload.get("days") or 30)
    user_prompt = (payload.get("prompt") or "").strip()
    econ_code   = (payload.get("econ_code") or "").strip()

    if not ticker:
        return JsonResponse({"error": "ticker is required"}, status=400)

    # --- 1Ô∏è‚É£ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏à‡∏≤‡∏Å ClickHouse ---
    try:
        rows = ch_fetch_price(ticker, days=days)
    except Exception as e:
        return JsonResponse({"error": f"Database fetch error: {e}"}, status=500)

    if not rows:
        return JsonResponse({"error": f"No data for ticker={ticker}"}, status=404)

    price_lines = []
    for d, o, h, l, c, adjc, v in rows:
        o = float(o) if o is not None else None
        h = float(h) if h is not None else None
        l = float(l) if l is not None else None
        c = float(c) if c is not None else None
        adjc = float(adjc) if adjc is not None else None
        v = int(v) if v is not None else 0
        price_lines.append(f"{d} O:{o} H:{h} L:{l} C:{c} AdjC:{adjc} V:{v}")
    price_block = "\n".join(price_lines)

    # --- 2Ô∏è‚É£ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏à‡∏≤‡∏Å Postgres ORM ---
    from warehouse.models import EconDailyFact, EconomicIndicator

    econ_info = {}
    for code in ["CPI", "REAL_GDP", "UNEMPLOYMENT"]:
        indicator = EconomicIndicator.objects.filter(code=code).first()
        if indicator:
            latest = (
                EconDailyFact.objects.filter(indicator=indicator)
                .select_related("date")
                .order_by("-date__date")
                .first()
            )
            if latest:
                econ_info[code] = {
                    "name": indicator.name,
                    "unit": indicator.unit,
                    "value": float(latest.value),
                    "date": latest.date.date.strftime("%Y-%m-%d")
                }

    econ_summary = "\n".join([
        f"‚Ä¢ {econ_info[c]['name']} ({c}) = {econ_info[c]['value']} {econ_info[c]['unit']} ({econ_info[c]['date']})"
        for c in econ_info
    ]) or "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

    # --- 3Ô∏è‚É£ ‡∏£‡∏ß‡∏° block ‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å econ_code ---
    econ_block = ""
    if econ_code:
        if econ_code in econ_info:
            e = econ_info[econ_code]
            econ_block = f"\n\n‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î {econ_code}: {e['value']} {e['unit']} ({e['date']})"
        else:
            econ_block = f"\n\n[Warning: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {econ_code} ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•]"

    # --- 4Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI ---
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô {ticker} ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ:

üìä **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î**
{econ_summary}

üíπ **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô {ticker} {days} ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤‚Üí‡πÉ‡∏´‡∏°‡πà):**
{price_block}

{econ_block}

‡πÇ‡∏õ‡∏£‡∏î‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô:
1. ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏´‡∏•‡∏±‡∏Å (Trend)
2. ‡πÅ‡∏ô‡∏ß‡∏£‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ï‡πâ‡∏≤‡∏ô (Support / Resistance)
3. ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à (CPI, GDP, Unemployment)
4. ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô
5. ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô
"""

    if user_prompt:
        prompt += f"\n\n--- ‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ---\n{user_prompt}"

    # --- 5Ô∏è‚É£ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini ---
    try:
        resp = model.generate_content(prompt)
        answer = resp.text
    except Exception as e:
        return JsonResponse({"error": f"Gemini API error: {e}"}, status=500)

    # --- 6Ô∏è‚É£ ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏Å‡∏•‡∏±‡∏ö ---
    return JsonResponse({
        "ticker": ticker,
        "days": days,
        "econ_data_used": econ_info,
        "analysis": answer
    }, status=200)

